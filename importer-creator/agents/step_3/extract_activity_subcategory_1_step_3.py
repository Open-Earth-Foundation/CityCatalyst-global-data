import sys
import subprocess
import json
import pandas as pd
from state.agent_state import AgentState
from utils.create_prompt import create_prompt
from utils.agent_creation import create_coding_agent
from utils.json_output_cleaner import clean_json_output
from context.mappings.mappings_activities import activity_mappings


# TODO: Consider splitting this into two agents for type and name
def extract_activity_subcategory_1_step_3(
    state: AgentState,
):
    """
    This agent extracts the GPC 'activity_subcategory_1' from the information provided within the dataframe 'df'.

    Inputs:
        Input path to the csv file created by the prior agent.
        The dataframe loaded from the input path.
        The context for identifying the GPC activity names.
        The user input context about the datafile.
        The python script generated by the prior agent.
        Output path for the generated files.
    """
    print("\nEXTRACT ACTIVITY SUBCATEGORY 1 STEP 3\n")

    # Load the output files of initial script
    input_path_csv = "./generated/step_3/steps/extracted_activity_unit.csv"
    input_path_script = (
        "./generated/step_3/steps/generated_script_extracted_activity_unit.py"
    )

    # Load the csv file into the dataframe
    df = pd.read_csv(input_path_csv, encoding="utf-8")
    # Load the script
    with open(input_path_script, "r", encoding="utf-8") as file:
        script = file.read()

    # Define the output paths
    output_path_csv = "./generated/step_3/steps/extracted_activity_subcategory_1.csv"
    output_path_script = (
        "./generated/step_3/steps/generated_script_extracted_activity_subcategory_1.py"
    )
    output_path_markdown = "./generated/step_3/steps/generated_markdown_extracted_activity_subcategory_1.md"

    task = """
Your task is to extract the Global Protocol for Community-Scale Greenhouse Gas Emission Inventories (GPC) 'activity_subcategory_type1' and 'activity_subcategory_typename1' from the provided python pandas dataframe based on the instructions below. You will also create a runnable python script.
These values are a more detailed description of the activity name provided inside the column 'activity_name' of the dataframe 'df'. 
It consists of a specific type 'activity_subcategory_type1' and name 'activity_subcategory_typename1', that further categorizes the activity. The possible values for both fields are provided in the 'activity_subcategories1' key of the 'activity_mappings' dictionary within <mappings_activities> tags.
Your inputs are:
- the input path to the .csv file created by the prior agent under <input_path> tags below,
- the dataframe 'df', 
- the user provided context in <user_context> tags,
- the prior script provided below inside <prior_script> tags, 
- and additional context for identidying activities in <mappings_activities> tags. 
- the output path for the new .csv file under <output_path> tags.
"""

    completion_steps = f"""
a. Inspect the .csv file provided under <input_path> tags below. You are provided with a pandas dataframe 'df' based on this .csv file. Base your further analysis only on this dataframe 'df'. This is already an updated dataframe based on the python script under <prior_script> tags below.
    - NEVER load the .csv file saved in the 'original_path' variable inside the script under <prior_script> tags below.  
b. Inspect the user provided context in <user_context> tags for information on the type of activity like fuel combustion or energy consumption or any other relevant information like specific fuel types or energy types.
c. Inspect the additional context for identifying the GPC activities subcategories in <mappings_activities> tags.
d. Inspect the provided python script under <prior_script> tags.
e. Determine the GPC 'activity_subcategory_type1' based on the content of the dataframe 'df', the user provided context in <user_context> tags and the additional context provided within <mappings_activities> tags. 
- To do this, inspect the column 'activity_name' of the dataframe 'df'.
- Then map the 'activity_name' of this column to the 'type' key inside the 'activity_subcategories1' key of the corresponding activity name key (e.g. 'fuel_combustion' or 'electricity_consumption') inside the mapping dictionary provided within <mappings_activities> tags below for each row.
f. Identify columns in the dataframe 'df' that help to determine the GPC 'activity_subcategory_typename1' based on the content of the dataframe 'df', the user provided context in <user_context> tags and the additional context provided within <mappings_activities> tags. 
- These could be columns describing the specific type of energy being used like a specific fuel type or energy type.
- Then map these identified columns to the 'name' key inside the 'activity_subcategories1' key of the corresponding activity name key (e.g. 'fuel_combustion' or 'electricity_consumption') inside the mapping dictionary provided within <mappings_activities> tags below for each row.
g. Create a python script based on the script provided within <prior_script> tags. This python script must contain the following:
    1. the original code of the prior script provided in the <prior_script> tags. You make your changes to this script. 
    2. a mapping dictionary for the GPC 'activity_subcategory_type1' based on your prior analysis in step 'e'.
    3. add a column 'activity_subcategory_type1' to the dataframe 'df_new' which applies a mapping for the GPC 'activity_subcategory_type1' to each row of 'df_new' based on the created mapping dictionary.
    4. a mapping dictionary for the GPC 'activity_subcategory_typename1' based on your prior analysis in step 'f'.
    5. add a column 'activity_subcategory_typename1' to the dataframe 'df_new' which applies a mapping for the GPC 'activity_subcategory_typename1' to each row of 'df_new' based on the created mapping dictionary.
    6. finally:
    - add code to output a new .csv file 'df_new.to_csv' so that the new .csv file contains the new dataframe 'df_new' with the changes made above. The new .csv file must be comma seperated ','. The .csv file must use 'encoding="utf-8"'.
    - store the new path given in <output_path> tags below in the updated variable named 'output_path' for exporting the new .csv file.
    
    IMPORTANT: 
    - The code must contain python comments.
    - The code must be executable and must not contain any code errors.
    - The new script must contain all the content of the initial script in addition to the added data.
    - **NEVER** replace the variable 'original_path' in the script loaded from <prior_script> tags.
"""

    answer_format = """
Your output must be provided in JSON format. Provide all detailed reasoning in a structured and human readable way (e.g. using sub headers, bulletpoints and numbered lists) and the pure executable Python code in the following JSON format:
{
    "reasoning": "Your detailed reasoning here...",
    "code": "Your pure executable Python code here..."
}
Ensure that the output is valid JSON and does not include any additional commentary or explanation. Do not surround the JSON ooutput with any code block markers or tags like ```json```.
"""
    additional_information = f"""
<additional_information>
<input_path>
This is the input path to the .csv file created by the prior agent: {input_path_csv}
</input_path>
<user_context>
This is the user context provided: {state.get("user_input")}. If there are conflicting values between different sources, use this user context as the highest priority.
</user_context>
<mappings_activities>
This is the additional context provided for identifying the activities: {json.dumps(activity_mappings, indent=4)}.
</mappings_activities>
<prior_script>
This is the prior python script provided:
    
```python
{script}
```
</prior_script>
<output_path>
This is the output path for the new .csv file: {output_path_csv}
</output_path>
</additional_information>
"""

    prompt = create_prompt(
        task, completion_steps, answer_format, additional_information
    )

    # Create agent
    agent = create_coding_agent(df, state.get("verbose"))

    # Invoke summary agent with custom prompt
    response = agent.invoke(prompt)
    response_output = response.get("output")

    # Check and potentially clean the JSON output by removing ```json``` code block markers
    cleaned_response_output = clean_json_output(response_output)

    ### Code below for extracting the code from the agent's response and running it - creating the csv file ###
    # Function to parse the JSON response from the agent
    def parse_agent_response(response):
        try:
            response_dict = json.loads(response)
            reasoning = response_dict.get("reasoning", "").strip()
            code = response_dict.get("code", "").strip()
            return {"reasoning": reasoning, "code": code}
        except json.JSONDecodeError as e:
            print(f"JSON decoding failed: {e}")
            sys.exit(1)

    # Parse the agent's response
    output = parse_agent_response(cleaned_response_output)

    # Save the reasoning to a Markdown file
    if output.get("reasoning"):
        with open(output_path_markdown, "w", encoding="utf-8") as markdown_file:
            markdown_file.write(f"# Reasoning\n\n{output['reasoning']}")
    else:
        print("No reasoning was found in the agent's response.")
        sys.exit(1)

    # Save the generated code to a Python file
    if output.get("code"):
        print("Create the script...")
        with open(output_path_script, "w", encoding="utf-8") as script_file:
            script_file.write(output["code"])

        # Run the generated Python script
        print("Attempting to run the generated script...")
        try:
            result = subprocess.run([sys.executable, output_path_script], check=True)
            print("The generated script was executed successfully.")
        except subprocess.CalledProcessError as e:
            print(f"An error occurred while executing the script: {e}")
            sys.exit(1)
    else:
        print("No Python code was found in the agent's response.")
        sys.exit(1)
