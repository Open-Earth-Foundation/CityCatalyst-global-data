import sys
import subprocess
import json
import pandas as pd
from state.agent_state import AgentState
from utils.create_prompt import create_prompt
from utils.agent_factory import AgentFactory
from context.mappings.mappings_white_list import white_list_mapping
from utils.create_descriptive_stats_prompt import create_descriptive_stats_prompt
from utils.file_paths_updater import update_file_paths


def datatypes_agent_initial_script(state: AgentState):
    """
    This agent is responsible for checking and potentially correcting the datatypes of the columns.

    Inputs:
        Input path to the csv file created by the prior agent.
        The dataframe loaded from the input path.
        White list of columns containing the standard data types.
        The python script generated by the prior agent.
    """
    print("\nFIX DATATYPES AGENT INITIAL SCRIPT\n")

    # Get pre-initialized agents from the AgentFactory
    structured_output_agent = AgentFactory.get_structured_output_agent(
        state.get("verbose")
    )
    # agent = AgentFactory.get_coding_agent(df_original, state.get("verbose"))

    # Load the previously created formatted csv file into a pandas dataframe
    input_path_csv = "./generated/initial_script/steps/2_deleted_columns.csv"
    input_path_script = "./generated/initial_script/steps/2_deleted_columns.py"

    # Load the csv file into the dataframe
    df = pd.read_csv(input_path_csv, encoding="utf-8")

    # Get pre-initialized agents from the AgentFactory
    structured_output_agent = AgentFactory.get_structured_output_agent(
        state.get("verbose")
    )
    agent = AgentFactory.get_coding_agent(df, state.get("verbose"))

    descriptive_statistics = create_descriptive_stats_prompt(df)
    # Load the script
    with open(input_path_script, "r", encoding="utf-8") as file:
        script = file.read()

    output_path_csv = "./generated/initial_script/steps/3_datatypes.csv"
    output_path_script = "./generated/initial_script/steps/3_datatypes.py"
    output_path_markdown = "./generated/initial_script/steps/3_datatypes.md"

    task = """
Your task is to inspect and correct the datatypes of columns of the provided DataFrame 'df'. You will also create a runnable python script.
Your inputs are:
- the input path to the .csv file created by the prior agent under <input_path> tags below.
- the dataframe 'df' loaded from the .csv file created by the prior agent
- the python script created by the prior agent provided below inside <prior_script> tags
- information about data trypes provided below in <white_list> tags.
"""
    completion_steps = f"""
a. Inspect the .csv file provided under <input_path> tags below. The dataframe 'df' you are provided with is the result of running the python script under <prior_script> tags below on this input .csv file.
    - Load the .csv file into a pandas dataframe 'df' using the path provided under <input_path> tags and 'df = pd.read_csv(input_path, encoding="utf-8", sep=",")'.
    - **NEVER** load the .csv file saved in the 'original_path' variable inside the script under <prior_script> tags.  
b. Inspect the datatypes of each column in the dataframe 'df' and output a list of suggested corrections. 
c. Inspect the columns in the dataframe 'df' that contain dates and temporal data. Check if those columns have the correct datatype for dates. 
    - determine the format being used e.g. '%Y' for '2023' or '%Y-%m' for '2023-10' or '%Y-%m-%d' for '2023-10-18'.
    - infer the format if it's not explicitly provided.
    - pay attention to columns that might not be clearly labeled as 'date' or 'dates' or similar but that still contain dates and temporal data. Those can be identified by numbers resembling years, months, days, etc.
d. Determine the correct datatypes for the other columns. Use the provided context in <white_list> tags to determine the correct datatypes for each column.
    - If you enounter a numeric column, analyze the decimal seperator that is being used and make sure the numbers are interpreted correctly.
    - If a decimal seperator other than '.' is being used, make sure to convert the numbers using '.' as the decimal seperator. The numbers never contain thousands separators.
e. Inspect the provided python script under <prior_script> tags.
f. Update the provided python script in <prior_script> tags below. This python script must contain the following:
    1. the original code of the prior script provided in the <prior_script> tags. You make your changes to this script.
    2. corrected datatypes for the columns in the dataframe 'df_new' based on your prior analysis.
    3. converted date columns to valid datetime data type based on your prior analysis.
    - Use the following code snippet:
    ```python
    format = '...'
    pd.to_datetime(..., format=format, errors='coerce')
    ```
    4. Insert the new code at the bottom of the script and before the final output to csv, to keep the chronological order of the script.
    5. **ONLY** insert the new code and **NEVER** overwrite or change the existing code. **NEVER** change the variable 'original_path'.
    
    IMPORTANT: 
    - **DO NOT** load the .csv file saved in the 'original_path' variable inside the script under <prior_script> tags below. You only work with the dataframe 'df' you are already provided with.
    - The code must contain python comments explaining the code.
    - The code must be executable and must not contain any code errors.
    - The new script must contain all the content of the initial script in addition to the added data.
"""
    answer_format = """
Your output must be provided in JSON format. Provide all detailed reasoning in a structured and human readable way (e.g. using sub headers, bulletpoints and numbered lists) and the pure executable Python code in the following JSON format:
{
    "reasoning": "Your detailed reasoning here...",
    "code": "Your pure executable Python code here..."
}
Ensure that the output is valid JSON and does not include any additional commentary or explanation. Do not surround the JSON ooutput with any code block markers or tags like ```json```.
"""
    additional_information = f"""
<additional_information>
<input_path>
This is the input path to the .csv file created by the prior agent: {input_path_csv}
</input_path>
<white_list>
This list provides information on datatypes for each column type: {json.dumps(white_list_mapping, indent=4)}
</white_list>
<prior_script>
This is the prior python script provided:
    
```python
{script}
```
</prior_script>
</additional_information>
"""

    prompt = create_prompt(
        task, completion_steps, answer_format, additional_information
    )

    # Invoke summary agent with custom prompt
    response = agent.invoke(descriptive_statistics + prompt)
    response_output = response.get("output")

    # Invoke the new structured output agent with the parsing task
    structured_output = structured_output_agent.invoke(response_output)

    ### Code below for extracting the code from the agent's response and running it - creating the csv file ###
    # Function to parse the JSON response from the agent
    def parse_agent_response(response):
        try:
            # Load the pydantic object into JSON
            response_json = response.json()
            # Load the JSON into a dictionary
            response_dict = json.loads(response_json)
            reasoning = response_dict.get("reasoning", "").strip()
            code = response_dict.get("code", "").strip()
            return {"reasoning": reasoning, "code": code}
        except json.JSONDecodeError as e:
            print(f"JSON decoding failed: {e}")
            sys.exit(1)

    # Parse the agent's response
    output = parse_agent_response(structured_output)

    # Save the reasoning to a Markdown file
    if output.get("reasoning"):
        with open(output_path_markdown, "w", encoding="utf-8") as markdown_file:
            markdown_file.write(f"# Reasoning\n\n{output['reasoning']}")
    else:
        print("No reasoning was found in the agent's response.")
        sys.exit(1)

    if output.get("code"):
        print("Update file paths...")
        # Update the generated code to replace the file paths dynamically
        updated_code = update_file_paths(
            output["code"], state.get("full_path"), output_path_csv
        )

        print("Create the script...")
        # Save the generated code to a Python file
        with open(output_path_script, "w", encoding="utf-8") as script_file:
            script_file.write(updated_code)

        # Run the generated Python script
        print("Attempting to run the generated script...")
        try:
            result = subprocess.run([sys.executable, output_path_script], check=True)
            print("The generated script was executed successfully.")
        except subprocess.CalledProcessError as e:
            print(f"An error occurred while executing the script: {e}")
            sys.exit(1)
    else:
        print("No Python code was found in the agent's response.")
        sys.exit(1)
