import sys
import subprocess
import json
import pandas as pd
from state.agent_state import AgentState
from utils.create_prompt import create_prompt
from utils.agent_factory import AgentFactory
from context.mappings.mappings_sub_sector import sub_sector_mapping
from utils.create_descriptive_stats_prompt import create_descriptive_stats_prompt
from utils.output_path_updater import update_output_path


def extract_sub_sector_agent_step_2(
    state: AgentState,
):
    """
    This agent extracts the GPC 'sub_sector' based on the content of the dataframe 'df', the provided user context and a mapping dictionary for the sub-sectors.

    Inputs:
        Input path to the csv file created by the prior agent.
        The dataframe loaded from the input path.
        The user input context about the datafile.
        The context for identifying the GPC sub-sector.
        The python script generated by the prior agent.
    """
    print("\nEXTRACT SUB-SECTOR AGENT STEP 2\n")

    # Load the output files of initial script
    input_path_csv = "./generated/step_2/steps/4_sector.csv"
    input_path_script = "./generated/step_2/steps/4_sector.py"

    # Load the csv file into the dataframe
    df = pd.read_csv(input_path_csv, encoding="utf-8")

    # Get pre-initialized agents from the AgentFactory
    structured_output_agent = AgentFactory.get_structured_output_agent(
        state.get("verbose")
    )
    agent = AgentFactory.get_coding_agent(df, state.get("verbose"))

    descriptive_statistics = create_descriptive_stats_prompt(df)
    # Load the script
    with open(input_path_script, "r", encoding="utf-8") as file:
        script = file.read()

    # Define the output paths
    output_path_csv = "./generated/step_2/steps/5_sub_sector.csv"
    output_path_script = "./generated/step_2/steps/5_sub_sector.py"
    output_path_markdown = "./generated/step_2/steps/5_sub_sector.md"

    task = """
Your task is to extract the Global Protocol for Community-Scale Greenhouse Gas Emission Inventories (GPC) sub-sector from the provided python pandas dataframe based on instructions below. You will also create a runnable python script.
Your inputs are:
- the input path to the .csv file created by the prior agent under <input_path> tags below,
- the dataframe 'df' loaded from the .csv file created by the prior agent, 
- the prior script provided below inside <prior_script> tags, 
- the user provided context in <user_context> tags,
- additional context for identidying the GPC sub-sector in <context_sub_sector> tags,
"""

    completion_steps = f"""
a. Inspect the .csv file provided under <input_path> tags below. The dataframe 'df' you are provided with is the result of running the python script under <prior_script> tags below on this input .csv file.
    - Load the .csv file into a pandas dataframe 'df' using the path provided under <input_path> tags and 'df = pd.read_csv(input_path, encoding="utf-8", sep=",")'.
    - **NEVER** load the .csv file saved in the 'original_path' variable inside the script under <prior_script> tags.  
b. Inspect the user provided context in <user_context> tags for information about the GPC sub-sectors present in the dataset.
c. Inspect the additional context for identifying the GPC sub-sector in <context_sub_sector> tags.
d. Identify further columns in the dataframe 'df' that help to determine the GPC sub-sector using the provided context in <context_sub_sector> tags below. These might be columns containing information about how and where the emissions occur, e.g. energy consumption in buildings or fuel combustion of certain vehicles like cars, ships, planes, trains and others which indicate the relevant GPC sub-sector.
- Print out the unique values of these identified columns to make sure that all unique values are accounted for in your answer.
e. Create a nested mapping dictionary that links the unique values of the column 'sector_name' and the unique values of the identified further columns that help identifying the GPC sub-sectors based on the provided context in <context_sub_sector> tags. The GPC sub-sector must be linked to the GPC sector and additional identified columns.
- Inspect the values of the column 'sector_name' and print out the unique values of this column. The possible values for the GPC sub-sector depend on the provided GPC sector. 
- The mapping should be a tuple of the form '('sector_name', 'further_column_a_value', 'furhter_column_b_value', ...)' as key and the GPC sub-sector as value, where further_column_a and further_column_b are possible columns that help to identify the GPC sub-sector.
- If the column 'sector_name' contains the value 'None', apply the same value 'None' the GPC sub-sector as 'None: None' without using a tuple and flag this in your reasoning.
f. Inspect the provided python script under <prior_script> tags.
g. Update the provided python script in <prior_script> tags below. This python script must contain the following:
    1. the original code of the prior script provided in the <prior_script> tags. You make your changes to this script. 
    2. a mapping dictionary for the GPC sub-sector based on your prior analysis.
    3. add a column 'subsector_name' to the dataframe 'df_new' which applies a GPC sub-sector to each row of 'df_new' based on the created mapping dictionary.
    4. Insert the new code at the bottom of the script and before the final output to csv, to keep the chronological order of the script.

    
    IMPORTANT: 
    - **DO NOT** load the .csv file saved in the 'original_path' variable inside the script under <prior_script> tags below. You only work with the dataframe 'df' you are already provided with.
    - The code must contain python comments explaining the code.
    - The code must be executable and must not contain any code errors.
    - The new script must contain all the content of the initial script in addition to the added data.
"""

    answer_format = """
Your output must be provided in JSON format. Provide all detailed reasoning in a structured and human readable way (e.g. using sub headers, bulletpoints and numbered lists) and the pure executable Python code in the following JSON format:
{
    "reasoning": "Your detailed reasoning here...",
    "code": "Your pure executable Python code here..."
}
Ensure that the output is valid JSON and does not include any additional commentary or explanation. Do not surround the JSON output with any code block markers or tags like ```json```.
"""
    additional_information = f"""
<additional_information>
<input_path>
This is the input path to the .csv file created by the prior agent: {input_path_csv}
</input_path>
<user_context>
This is the user context provided: {state.get("user_input")}. If there are conflicting values between different sources, use this user context as the highest priority.
</user_context>
<context_sub_sector>
This is the additional context provided for identifying the GPC sub-sector: {json.dumps(sub_sector_mapping, indent=4)}.
</context_sub_sector>
<prior_script>
This is the prior python script provided:
    
```python
{script}
```
</prior_script>
</additional_information>
"""

    prompt = create_prompt(
        task, completion_steps, answer_format, additional_information
    )

    # Invoke summary agent with custom prompt
    response = agent.invoke(descriptive_statistics + prompt)
    response_output = response.get("output")

    # Invoke the new structured output agent with the parsing task
    structured_output = structured_output_agent.invoke(response_output)

    ### Code below for extracting the code from the agent's response and running it - creating the csv file ###
    # Function to parse the JSON response from the agent
    def parse_agent_response(response):
        try:
            # Load the pydantic object into JSON
            response_json = response.json()
            # Load the JSON into a dictionary
            response_dict = json.loads(response_json)
            reasoning = response_dict.get("reasoning", "").strip()
            code = response_dict.get("code", "").strip()
            return {"reasoning": reasoning, "code": code}
        except json.JSONDecodeError as e:
            print(f"JSON decoding failed: {e}")
            sys.exit(1)

    # Parse the agent's response
    output = parse_agent_response(structured_output)

    # Save the reasoning to a Markdown file
    if output.get("reasoning"):
        with open(output_path_markdown, "w", encoding="utf-8") as markdown_file:
            markdown_file.write(f"# Reasoning\n\n{output['reasoning']}")
    else:
        print("No reasoning was found in the agent's response.")
        sys.exit(1)

    # Save the generated code to a Python file
    if output.get("code"):
        print("Update output path...")
        # Update the generated code to replace the 'output_path' dynamically
        updated_code = update_output_path(output["code"], output_path_csv)

        print("Create the script...")
        # Save the generated code to a Python file
        with open(output_path_script, "w", encoding="utf-8") as script_file:
            script_file.write(updated_code)

        # Run the generated Python script
        print("Attempting to run the generated script...")
        try:
            result = subprocess.run([sys.executable, output_path_script], check=True)
            print("The generated script was executed successfully.")
        except subprocess.CalledProcessError as e:
            print(f"An error occurred while executing the script: {e}")
            sys.exit(1)
    else:
        print("No Python code was found in the agent's response.")
        sys.exit(1)
